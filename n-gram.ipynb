{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/indra622/python-ngram/blob/master/n-gram.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Bexr_jrbV3yk"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/indra622/python-ngram.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "DixdHrrSV75U"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/content/python-ngram/train.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-4867d837a6c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/python-ngram/train.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/python-ngram/test.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/python-ngram/train.txt'"
     ]
    }
   ],
   "source": [
    "with open('/content/python-ngram/train.txt', 'r') as f:\n",
    "    train = [i.strip() for i in f.readlines()]\n",
    "with open('/content/python-ngram/test.txt', 'r') as f:\n",
    "    test = [i.strip() for i in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xFy8qFkVV-mC"
   },
   "outputs": [],
   "source": [
    "SOS = '<s>'\n",
    "EOS = '</s>'\n",
    "\n",
    "sentences = [ '{} {} {}'.format(SOS, s, EOS) for s in train]\n",
    "tokens = ' '.join(sentences).split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U1rnI_thWBM_",
    "outputId": "fc70a297-7d1b-4449-e96a-23237c195084"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('<s>', 'K.') 0.6666666666666666\n",
      "('K.', 'Cay') 0.5\n",
      "('Cay', '</s>') 1.0\n",
      "('</s>', '<s>') 0.6666666666666666\n",
      "('K.', 'Ache') 0.5\n",
      "('Ache', '</s>') 1.0\n",
      "('<s>', 'Cay') 0.3333333333333333\n"
     ]
    }
   ],
   "source": [
    "n = 2\n",
    "vocab = nltk.FreqDist(tokens)\n",
    "\n",
    "if n == 1:\n",
    "    num_tokens = len(tokens)\n",
    "    ngram = { unigram : count / num_tokens for unigram, count in vocab.items() }\n",
    "\n",
    "else:\n",
    "    vocab_size = len(vocab)\n",
    "    ngrams = nltk.ngrams(tokens, n)\n",
    "    pgrams = nltk.ngrams(tokens, n-1)\n",
    "    nvocab = nltk.FreqDist(ngrams)\n",
    "    pvocab = nltk.FreqDist(pgrams)\n",
    "    cnt = {}\n",
    "    for gram, count in pvocab.items():\n",
    "        cnt[gram] = count\n",
    "    ngram = {}\n",
    "    for gram, count in nvocab.items():\n",
    "        pgram = gram[0:-1]\n",
    "        ngram[gram] = count/cnt[pgram]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0MrdHr89WDYq"
   },
   "outputs": [],
   "source": [
    "test_sentences = [ '{} {} {}'.format(SOS, s, EOS) for s in test]\n",
    "test_tokens = ' '.join(test_sentences).split(\" \")\n",
    "test_ngrams = nltk.ngrams(test_tokens, n)\n",
    "num_test_tokens = len(test_tokens)\n",
    "probabilities = [ ngram[ng] for ng in test_ngrams ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HuYdvkv2WFXZ"
   },
   "outputs": [],
   "source": [
    "ppl = math.exp((-1/num_test_tokens) * sum(map(math.log, probabilities)))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Untitled6.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
